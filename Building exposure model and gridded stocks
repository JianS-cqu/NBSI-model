####code 1

################################## code designed to building exposure model and gridded stocks #######################
#### This section of the code consists of 5 parts.
#### code 1.1 is employed to estimate building heights, morphology, and geometric parameters for each building in China(Section 2.1 in Supplementary materials).
#### code 1.2 is employed to estimate building age and use type in China(Section 2.2 in Supplementary materials).
#### code 1.3 is employed to ascertain the applicable seismic design provisions (Section 2.3 in Supplementary materials).
#### code 1.4 is employed to categorize structural types of Chinese buildings (Section 2.4 in Supplementary materials).
#### code 1.5 is employed to estimate gridded building inventory (Section 2.5 in Supplementary materials).

####  If you have any questions, please email Jian Sun: sunjian143687@163.com


#### packages
library(tidyverse)
library(sf)
library(terra)
library(raster)
library(randomForest)
library(fs)
library(jsonlite)
library(readxl)


#### Set working directory to simplify paths
setwd("/path/")


#### Code 1.1 Extract building height and physical attributes
#### Reads building footprint data and calculates physical properties like area, length, width, and orientation

read_sf("building_footprints.shp") %>%  #### The building footprints were extracted from the GABLE dataset
  mutate(idd = row_number()) %>%
  st_transform(crs = 3857) -> test

test %>%
  st_minimum_rotated_rectangle() %>%
  mutate(area1 = as.numeric(st_area(test))) %>%
  mutate(
    length_cal = map(geometry, function(geom) {
      coords <- st_coordinates(geom) %>%
        as_tibble() %>%
        distinct(X, Y, .keep_all = TRUE)
      bc1 <- sqrt((coords$X[1] - coords$X[2])^2 + (coords$Y[1] - coords$Y[2])^2)
      bc2 <- sqrt((coords$X[2] - coords$X[3])^2 + (coords$Y[2] - coords$Y[3])^2)
      cita1 <- asin((coords$Y[2] - coords$Y[1]) / sqrt((coords$X[2] - coords$X[1])^2 + (coords$Y[2] - coords$Y[1])^2)) * 180 / pi
      cita2 <- asin((coords$Y[3] - coords$Y[2]) / sqrt((coords$X[3] - coords$X[2])^2 + (coords$Y[3] - coords$Y[2])^2)) * 180 / pi
      tibble(bc1 = bc1, bc2 = bc2, cita1 = cita1, cita2 = cita2)
    })
  ) %>%
  unnest(length_cal) %>%
  st_drop_geometry() %>%
  mutate(area2 = bc1 * bc2,
         ra = area2 / area1,
         bc11 = bc1 / sqrt(ra),
         bc22 = bc2 / sqrt(ra)) %>%
  dplyr::select(idd, area1, bc11, bc22, cita1, cita2) -> xx

xx %>%
  write_csv("physical_properties.csv")


###### Height validation using building height raster data
rast("building_height.tif") %>%
  terra::extract(df1) %>%
  as_tibble() %>%
  na.omit() %>%
  split(.$ID) %>%
  map(function(x) x %>% arrange(-BH_prediction) %>% slice(1)) %>%
  bind_rows() %>%
  set_names("idd", "hh1") -> hh1

hh1 %>%
  write_csv("height_validation.csv")








##### Code 1.2 Estimation of building age and use type

read_csv("building_features.csv") -> a1  
read_csv("building_years.csv") -> yy  
read_csv("building_types.csv") %>%
  dplyr::select(iddd, build_type, new_age) -> a2  ##### the training data

a2 %>%
  full_join(yy) %>%
  dplyr::select(-build_type) -> lzz

lzz %>%
  na.omit() -> pp1
pp1 %>%
  dplyr::select(-new_age) %>%
  rename(year = buildYear) -> kk1

lzz %>%
  dplyr::filter(if_any(everything(), is.na)) -> pp2
pp2[is.na(pp2)] <- 0

pp2 %>%
  mutate(year = new_age + buildYear) %>%
  dplyr::select(iddd, year) -> kk2
kk1 %>%
  bind_rows(kk2) -> kk3

a2 %>%
  dplyr::select(-new_age) -> kk4
a1 %>%
  left_join(kk3) %>%
  left_join(kk4) -> df1

df1 %>%
  dplyr::filter(is.na(year)) -> test1
df1 %>%
  dplyr::filter(!is.na(year)) -> train1
train1 %>%
  dplyr::select(-iddd, -link1km, -poi, -buildYear, -build_type) -> train2

train2 %>%
  count(year) %>%
  mutate(prop = n / sum(n),
         lgy = round(5000 * prop)) %>%
  mutate(lgy = if_else(lgy == 0, n, lgy)) %>%
  dplyr::select(year, lgy) -> temp2

train2 %>%
  split(.$year) %>%
  map(function(x)
    x %>%
      sample_n(
        temp2 %>% dplyr::filter(year == unique(x$year)) %>%
          dplyr::select(lgy) %>% pull()
      )) %>%
  bind_rows() -> train33

randomForest(year ~ ., data = train33, importance = T) %>%
  predict(test1) -> tss_year

test1 %>%
  mutate(year = round(tss_year, digits = 0)) %>%
  bind_rows(train1) %>%
  write_csv("predicted_years.csv")




      
#### Code 1.3 Ascertain the applicable seismic design provisions
# Extracts seismic design parameters from GB18306 standard based on coordinates

read_csv("coordinates.csv") -> cdf

get_pga <- function(x, y, z) {
  fromJSON(paste0("https://www.gb18306.net/querykz?x=", x, "&y=", y, "&ak=c83dc409-03d8-433b-a41d-0c5f39d7265d&year=", z, "&kz=yes"))
}

# Batch processing of coordinates for seismic parameters
for (i in 1:nrow(cdf)) {
  print(i)
  if (!file.exists(paste0("seismic_js2015/J_", cdf$secc[i], "_", cdf$idd[i], ".json"))) {
    get_pga(cdf$lon[i], cdf$lat[i], 2015) %>%
      write_json(paste0("seismic_js2015/J_", cdf$secc[i], "_", cdf$idd[i], ".json"))
  }
}

# Processing county-level coordinates
read_csv("county_coordinates.csv") -> cdf

get_pga2 <- function(x, y, z) {
  fromJSON(paste0("https://www.gb18306.net/querykz?x=", x, "&y=", y, "&ak=c83dc409-03d8-433b-a41d-0c5f39d7265d&year=1985&kz=yes")) %>%
    write_json(paste0("seismic_js1985/J_", z, ".json"))
}

cdf %>%
  dplyr::select(-1) %>%
  set_names("x", "y", "z") %>%
  slice(c(2684:2878)) %>%
  mutate(jss = pmap(list(x, y, z), get_pga2))

# Process JSON results to extract seismic parameters
dir_ls('seismic_js1975/') %>%
  as.character() %>%
  as_tibble() -> df

eq_json <- function(path) {
  fromJSON(path) -> test
  test$ld -> a_ld
  return(a_ld)
}

df %>%
  set_names("path") %>%
  mutate(eqq = map(path, eq_json)) %>%
  mutate(eqq = map(eqq, function(x) {
    if (is.list(x)) {
      return(unlist(x))
    } else {
      return(x)
    }
  })) %>%
  unnest(eqq) -> df2

df2 %>%
  mutate(path = str_remove_all(path, "seismic_js1975/J_"),
         path = str_remove_all(path, ".json")) %>%
  mutate(path = as.numeric(path)) %>%
  rename(idd = path) -> df3

df3 %>%
  write_csv("seismic_parameters_1975.csv")













#### Code 1.4 Building structure classification

read_csv("building_data.csv") -> df33
df33 %>%
  dplyr::select(-type) -> df33

df33 %>%
  mutate(vol = high * area1) -> sj

sj %>%
  dplyr::filter(high > 21) -> rc1
rc1 %>%
  dplyr::select(iddd) %>%
  mutate(type = "rc") -> rc11

sj %>%
  dplyr::filter(high <= 21) %>%
  mutate(gkb = high / kuan) %>%
  dplyr::filter(gkb > 5) -> rc2
rc2 %>%
  dplyr::select(iddd) %>%
  mutate(type = "rc") -> rc22

sj %>%
  dplyr::filter(high <= 21) %>%
  mutate(gkb = high / kuan) %>%
  dplyr::filter(gkb <= 5) %>%
  dplyr::filter(poi == 1) -> rc3
rc3 %>%
  dplyr::select(iddd) %>%
  mutate(type = "rc") -> rc33

sj %>%
  dplyr::filter(high <= 21) %>%
  mutate(gkb = high / kuan) %>%
  dplyr::filter(gkb <= 5) %>%
  dplyr::filter(is.na(poi)) %>%
  dplyr::filter(build_type != 2) %>%
  dplyr::filter(area1 > 1000) -> rc2a
rc2a %>%
  dplyr::select(iddd) %>%
  mutate(type = "rc") -> rc22a

sj %>%
  dplyr::filter(high <= 21) %>%
  mutate(gkb = high / kuan) %>%
  dplyr::filter(gkb <= 5) %>%
  dplyr::filter(is.na(poi)) %>%
  dplyr::filter(build_type == 2) %>%
  dplyr::filter(area1 > 400) -> rc2b
rc2b %>%
  dplyr::select(iddd) %>%
  mutate(type = "rc") -> rc22b

rc11 %>%
  bind_rows(rc22) %>%
  bind_rows(rc33) %>%
  bind_rows(rc22a) %>%
  bind_rows(rc22b) -> rrcc

sj %>%
  left_join(rrcc) %>%
  dplyr::filter(is.na(type)) %>%
  dplyr::select(-type) -> sj1

# Wood structure classification
sj1 %>%
  dplyr::filter(lulc == 52) -> wd1
wd1 %>%
  dplyr::select(iddd) %>%
  mutate(type = "wd") -> wd11

sj1 %>%
  dplyr::filter(lulc != 52) %>%
  dplyr::filter(build_type == 6) -> wd2
wd2 %>%
  dplyr::select(iddd) %>%
  mutate(type = "wd") -> wd22

sj1 %>%
  dplyr::filter(lulc != 52) %>%
  dplyr::filter(build_type != 6) %>%
  dplyr::filter(high <= 3) %>%
  arrange(vol) %>%
  mutate(lgy = vol / sum(sj$vol)) %>%
  mutate(lgy1 = cumsum(lgy)) %>%
  dplyr::filter(lgy1 <= (code_wd - ww1 - ww2)) -> wd3
wd3 %>%
  dplyr::select(iddd) %>%
  mutate(type = "wd") -> wd33

rrcc %>%
  bind_rows(wd33) %>%
  bind_rows(wd11) %>%
  bind_rows(wd22) -> xff

sj %>%
  left_join(xff) %>%
  mutate(type = if_else(is.na(type), "bc", type)) -> sj1

sj1 %>%
  write_csv("building_structure_classification.csv")











#### Code 1.5 Material stock calculation

readxl::read_xlsx("material_intensity.xlsx") -> mii

eq_ms <- function(acode) {
  read_csv(paste0("building_data_", format(acode, scientific = FALSE), ".csv")) -> df
  read_csv(paste0("km_grid_", format(acode, scientific = FALSE), ".csv")) -> km
  
  df %>%
    dplyr::select(iddd, prov, high, area1, year, func, stru, hhh, epa) %>%
    mutate(epa = if_else(epa < 0.05, 0.05, epa)) %>%
    mutate(epa = if_else(is.na(epa), 0.05, epa)) %>%
    left_join(km) %>%
    mutate(cengg = 3.5) %>%
    mutate(cengg = if_else(func == "r" & high >= 18 & high < 36 & area1 >= 1000, 3.8, cengg)) %>%
    # ... (additional conditional mutations for cengg)
    mutate(year = if_else(year < 1970, 1970, year)) %>%
    mutate(prov = format(prov, scientific = FALSE)) %>%
    unite("link3", stru, func, prov) %>%
    mutate(flor = floor(high / cengg),
           flor = if_else(flor < 1, 1, flor)) %>%
    left_join(mii) %>%
    mutate(
      ms_Steel = (year * Steel_k + Steel_b) * area1 * flor / 1000,
      # ... (additional material calculations)
      ms_total = ms_Steel + ms_Aluminum + ms_Copper + ms_Wood + ms_Cement + 
                 ms_Brick + ms_Gravel + ms_Sand + ms_Asphalt + ms_Glass + 
                 ms_Plastic + ms_Rubber,
      hs_area = area1 * flor
    ) %>%
    dplyr::select(link3, hhh, epa, lon_1km, lat_1km, ms_Steel, ms_Aluminum, 
                  ms_Copper, ms_Wood, ms_Cement, ms_Brick, ms_Gravel, ms_Sand, 
                  ms_Asphalt, ms_Glass, ms_Plastic, ms_Rubber, ms_total) %>%
    separate(link3, into = c("stru", "func", "prov"), sep = "_") %>%
    dplyr::select(-prov) %>%
    unite("ztype", stru, func, epa, hhh) %>%
    unite("link5", lon_1km, lat_1km) %>%
    unite("link6", ztype, link5, sep = "=") -> df2
  
  # Aggregate and save material stocks by type
  df2 %>%
    split(.$link6) %>%
    map(function(x) dplyr::select(x, link6) %>% unique()) %>%
    bind_rows() -> tmp1
  
  df2 %>%
    split(.$link6) %>%
    map(function(x) dplyr::select(x, -link6) %>% colSums()) %>%
    bind_rows() -> tmp2
  
  data.frame(tmp1, tmp2) %>%
    as_tibble() %>%
    separate(link6, into = c("ztype", "link33"), sep = "=") -> df4
  
  # Save individual material stocks
  materials <- c("Steel", "Aluminum", "Copper", "Wood", "Cement", "Brick", 
                 "Gravel", "Sand", "Asphalt", "Glass", "Plastic", "Rubber", "total")
  
  for (mat in materials) {
    df4 %>%
      dplyr::select(ztype, link33, paste0("ms_", mat)) %>%
      split(.$ztype) %>%
      map(function(x)
        x %>% dplyr::select(-ztype) %>% 
          write_csv(paste0("material_stocks/", mat, "/", unique(x$ztype), "/ms_", acode, ".csv")))
  }
}

# Rasterization function for material stocks
js_rst <- function(mat, sss) {
  read_csv(paste0("material_stocks/", mat, "/", sss, ".csv")) %>%
    set_names("link33", "mss") -> kk
  
  cmod %>%
    left_join(kk) %>%
    mutate(mss = if_else(is.na(mss), 0, mss)) %>%
    dplyr::select(-tmp) %>%
    separate(link33, into = c("lon", "lat"), sep = "_") %>%
    st_as_sf(coords = c("lon", "lat"), crs = crss) -> df1
  
  rast(ext(df1), resolution = c(1000, 1000),
       crs = "+proj=moll +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs") -> raster_template
  
  rasterize(vect(df1), raster_template, field = "mss") -> rst
  rst %>%
    project(mod) %>%
    resample(mod, method = "near") -> rst1
  
  names(rst1) <- mat
  origin(rst1) <- c(0, 0)
  rst1 %>%
    writeRaster(paste0("material_rasters/", mat, "/", sss, ".tif"), overwrite = TRUE)
}






      
      
